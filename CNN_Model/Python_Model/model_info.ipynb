{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726fa9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor                                         N \t\t\t\t    Scale \t\t\t\t ZeroPt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "serving_default_keras_tensor_30:0         120000 \t\t\t\t 0.003921568859368563 \t\t\t\t      0\n",
      "arith.constant                                 2 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst                             29 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst1                         14848 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst2                           512 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst3                        37748736 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst4                           512 \t\t\t\t 0.005283291917294264 \t\t\t\t    113\n",
      "tfl.pseudo_qconst5                           512 \t\t\t\t 0.1490822583436966 \t\t\t\t   -128\n",
      "tfl.pseudo_qconst6                           512 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst7                        2359296 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst8                           512 \t\t\t\t 0.003270635614171624 \t\t\t\t     70\n",
      "tfl.pseudo_qconst9                           512 \t\t\t\t 0.0017053347546607256 \t\t\t\t   -128\n",
      "tfl.pseudo_qconst10                          512 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst11                       1179648 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst12                          256 \t\t\t\t 0.003829863155260682 \t\t\t\t     87\n",
      "tfl.pseudo_qconst13                          256 \t\t\t\t 0.09097450226545334 \t\t\t\t   -128\n",
      "tfl.pseudo_qconst14                          256 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst15                       589824 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst16                          256 \t\t\t\t 0.008151660673320293 \t\t\t\t     78\n",
      "tfl.pseudo_qconst17                          256 \t\t\t\t 0.0010407568188384175 \t\t\t\t   -128\n",
      "tfl.pseudo_qconst18                          256 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst19                       294912 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst20                          128 \t\t\t\t 0.004105701111257076 \t\t\t\t    127\n",
      "tfl.pseudo_qconst21                          128 \t\t\t\t 0.001115808729082346 \t\t\t\t   -128\n",
      "tfl.pseudo_qconst22                          128 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst23                       147456 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst24                          128 \t\t\t\t 0.004118925426155329 \t\t\t\t    109\n",
      "tfl.pseudo_qconst25                          128 \t\t\t\t 0.001440622960217297 \t\t\t\t   -128\n",
      "tfl.pseudo_qconst26                          128 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst27                        73728 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst28                           64 \t\t\t\t 0.0061034648679196835 \t\t\t\t    127\n",
      "tfl.pseudo_qconst29                           64 \t\t\t\t 0.010403404012322426 \t\t\t\t   -128\n",
      "tfl.pseudo_qconst30                           64 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst31                        36864 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst32                           64 \t\t\t\t 0.02051985077559948 \t\t\t\t    107\n",
      "tfl.pseudo_qconst33                           64 \t\t\t\t 0.17310108244419098 \t\t\t\t   -128\n",
      "tfl.pseudo_qconst34                           64 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.pseudo_qconst35                         1728 \t\t\t\t      0.0 \t\t\t\t      0\n",
      "tfl.quantize                              120000 \t\t\t\t 0.003921568859368563 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/conv2d_1/Relu;sequential_1_1/sequential_1/conv2d_1/BiasAdd;sequential_1_1/sequential_1/conv2d_1/convolution;1  2560000 \t\t\t\t 0.14930161833763123 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_1/batchnorm/mul_1  2560000 \t\t\t\t 0.1682112067937851 \t\t\t\t    -99\n",
      "sequential_1_1/sequential_1/batch_normalization_1/batchnorm/add_1  2560000 \t\t\t\t 0.16808736324310303 \t\t\t\t    -99\n",
      "sequential_1_1/sequential_1/conv2d_1_2/Relu;sequential_1_1/sequential_1/conv2d_1_2/BiasAdd;sequential_1_1/sequential_1/conv2d_1_2/convolution;sequential_1_1/sequential_1/conv2d_1_2/Squeeze  2560000 \t\t\t\t 0.4822568893432617 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_1_2/batchnorm/mul_1  2560000 \t\t\t\t 0.48836034536361694 \t\t\t\t   -125\n",
      "sequential_1_1/sequential_1/batch_normalization_1_2/batchnorm/add_1  2560000 \t\t\t\t 0.487743616104126 \t\t\t\t   -125\n",
      "sequential_1_1/sequential_1/max_pooling2d_1/MaxPool2d  640000 \t\t\t\t 0.487743616104126 \t\t\t\t   -125\n",
      "sequential_1_1/sequential_1/conv2d_2_1/Relu;sequential_1_1/sequential_1/conv2d_2_1/BiasAdd;sequential_1_1/sequential_1/conv2d_2_1/convolution;  1280000 \t\t\t\t 0.5958064198493958 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_2_1/batchnorm/mul_1  1280000 \t\t\t\t 0.1463908702135086 \t\t\t\t   -121\n",
      "sequential_1_1/sequential_1/batch_normalization_2_1/batchnorm/add_1  1280000 \t\t\t\t 0.14274635910987854 \t\t\t\t   -121\n",
      "sequential_1_1/sequential_1/conv2d_3_1/Relu;sequential_1_1/sequential_1/conv2d_3_1/BiasAdd;sequential_1_1/sequential_1/conv2d_3_1/convolution;  1280000 \t\t\t\t 0.9574838280677795 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_3_1/batchnorm/mul_1  1280000 \t\t\t\t 0.09289126843214035 \t\t\t\t   -117\n",
      "sequential_1_1/sequential_1/batch_normalization_3_1/batchnorm/add_1  1280000 \t\t\t\t 0.09052053838968277 \t\t\t\t   -116\n",
      "sequential_1_1/sequential_1/max_pooling2d_1_2/MaxPool2d  320000 \t\t\t\t 0.09052053838968277 \t\t\t\t   -116\n",
      "sequential_1_1/sequential_1/conv2d_4_1/Relu;sequential_1_1/sequential_1/conv2d_4_1/BiasAdd;sequential_1_1/sequential_1/conv2d_4_1/convolution;  640000 \t\t\t\t 0.9490053653717041 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_4_1/batchnorm/mul_1  640000 \t\t\t\t 0.11567893624305725 \t\t\t\t   -114\n",
      "sequential_1_1/sequential_1/batch_normalization_4_1/batchnorm/add_1  640000 \t\t\t\t 0.11381451785564423 \t\t\t\t   -113\n",
      "sequential_1_1/sequential_1/conv2d_5_1/Relu;sequential_1_1/sequential_1/conv2d_5_1/BiasAdd;sequential_1_1/sequential_1/conv2d_5_1/convolution;  640000 \t\t\t\t 1.2002378702163696 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_5_1/batchnorm/mul_1  640000 \t\t\t\t 0.3943060338497162 \t\t\t\t   -126\n",
      "sequential_1_1/sequential_1/batch_normalization_5_1/batchnorm/add_1  640000 \t\t\t\t 0.39389708638191223 \t\t\t\t   -126\n",
      "sequential_1_1/sequential_1/max_pooling2d_2_1/MaxPool2d  160000 \t\t\t\t 0.39389708638191223 \t\t\t\t   -126\n",
      "sequential_1_1/sequential_1/conv2d_6_1/Relu;sequential_1_1/sequential_1/conv2d_6_1/BiasAdd;sequential_1_1/sequential_1/conv2d_6_1/convolution;  320000 \t\t\t\t 1.5455434322357178 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_6_1/batchnorm/mul_1  320000 \t\t\t\t 0.15267038345336914 \t\t\t\t   -124\n",
      "sequential_1_1/sequential_1/batch_normalization_6_1/batchnorm/add_1  320000 \t\t\t\t 0.15163584053516388 \t\t\t\t   -124\n",
      "sequential_1_1/sequential_1/conv2d_7_1/Relu;sequential_1_1/sequential_1/conv2d_7_1/BiasAdd;sequential_1_1/sequential_1/conv2d_7_1/convolution;  320000 \t\t\t\t 1.0951658487319946 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_7_1/batchnorm/mul_1  320000 \t\t\t\t 0.6881277561187744 \t\t\t\t   -126\n",
      "sequential_1_1/sequential_1/batch_normalization_7_1/batchnorm/add_1  320000 \t\t\t\t 0.6877288222312927 \t\t\t\t   -126\n",
      "sequential_1_1/sequential_1/max_pooling2d_3_1/MaxPool2d   73728 \t\t\t\t 0.6877288222312927 \t\t\t\t   -126\n",
      "sequential_1_1/sequential_1/flatten_1/Reshape   73728 \t\t\t\t 0.6877288222312927 \t\t\t\t   -126\n",
      "sequential_1_1/sequential_1/dense_1/MatMul;sequential_1_1/sequential_1/dense_1/Relu;sequential_1_1/sequential_1/dense_1/BiasAdd     512 \t\t\t\t 4.46315336227417 \t\t\t\t   -128\n",
      "sequential_1_1/sequential_1/batch_normalization_8_1/batchnorm/mul_1;sequential_1_1/sequential_1/batch_normalization_8_1/batchnorm/add_1;sequential_1_1/sequential_1/logits_1/MatMul;sequential_1_1/sequential_1/logits_1/BiasAdd      29 \t\t\t\t 0.3223066031932831 \t\t\t\t    -18\n",
      "StatefulPartitionedCall_1:01                  29 \t\t\t\t 0.00390625 \t\t\t\t   -128\n",
      "StatefulPartitionedCall_1:0                   29 \t\t\t\t 0.00390625 \t\t\t\t      0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "interp = Interpreter(model_path=\"asl_model_quantized_int8.tflite\")\n",
    "interp.allocate_tensors()\n",
    "\n",
    "print(f\"{'Tensor':40s}  {'N':>6s} \\t\\t\\t\\t {'Scale':>8s} \\t\\t\\t\\t {'ZeroPt':>6s}\")\n",
    "print(\"-\"*166)\n",
    "for detail in interp.get_tensor_details():\n",
    "    name  = detail[\"name\"]\n",
    "    shape = detail[\"shape\"]\n",
    "    N     = int(np.prod(shape)) if shape is not None else 0\n",
    "\n",
    "    # Use the top‑level 'quantization' tuple when available\n",
    "    try:\n",
    "        scale, zero_point = detail[\"quantization\"]\n",
    "    except KeyError:\n",
    "        # Fallback to the parameters dict\n",
    "        scales = detail[\"quantization_parameters\"][\"scales\"]\n",
    "        zps    = detail[\"quantization_parameters\"][\"zero_points\"]\n",
    "        scale = float(scales[0])   if len(scales)  > 0 else None\n",
    "        zero_point = int(zps[0])   if len(zps)     > 0 else None\n",
    "\n",
    "    print(f\"{name:40s}  {N:6d} \\t\\t\\t\\t {str(scale):>8s} \\t\\t\\t\\t {str(zero_point):>6s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8913bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input round‑trip: True\n",
      "[[0.         0.         0.99609375 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donald/.local/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "/home/donald/.local/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:465: UserWarning: Warning: Enabling `experimental_preserve_all_tensors` with the BUILTIN or AUTO op resolver is intended for debugging purposes only. Be aware that this can significantly increase memory usage by storing all intermediate tensors. If you encounter memory problems or are not actively debugging, consider disabling this option.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "# 1) Load & prepare the interpreter\n",
    "interp = Interpreter(\n",
    "    model_path=\"asl_model_quantized_int8.tflite\",\n",
    "    experimental_preserve_all_tensors=True\n",
    ")\n",
    "interp.allocate_tensors()\n",
    "\n",
    "# 2) Load your JPG and resize to 200×200 RGB\n",
    "img = Image.open(\"asl_alphabet_test/C_test.jpg\").convert(\"RGB\")\n",
    "img = img.resize((200, 200), Image.BILINEAR)\n",
    "\n",
    "# 3) Turn into a (1,200,200,3) uint8 array\n",
    "arr = np.array(img, dtype=np.uint8)\n",
    "arr = arr[np.newaxis, ...]   # add batch dimension → shape (1,200,200,3)\n",
    "\n",
    "# 4) Find the input tensor index & set it\n",
    "input_details = interp.get_input_details()\n",
    "idx = input_details[0][\"index\"]          # usually 0\n",
    "# (you can also check input_details[0][\"shape\"] to confirm)\n",
    "interp.set_tensor(idx, arr)\n",
    "\n",
    "# 5) Invoke & then dump any tensor you like\n",
    "interp.invoke()\n",
    "out  = interp.get_tensor(input_details[0][\"index\"])  # just to verify\n",
    "print(\"input round‑trip:\", np.array_equal(out, arr))\n",
    "output_details = interp.get_output_details()\n",
    "\n",
    "out_info   = output_details[0]\n",
    "out_index  = out_info[\"index\"]\n",
    "q_output   = interp.get_tensor(out_index)           # e.g. shape (1,N), dtype=int8/uint8\n",
    "scale, zp  = out_info[\"quantization\"]               # float scale and int zero‑point\n",
    "# convert back to “real” floats if you like:\n",
    "real_output = scale * (q_output.astype(np.float32) - zp)\n",
    "print(real_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7589e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution steps (pure‑TFLite CPU ops):\n",
      "\n",
      "Step  0: QUANTIZE\n",
      "    IN  tensor #0: “serving_default_keras_tensor_30:0” shape=(1, 200, 200, 3), type=uint8, scale=0.003921568859368563, zp=0\n",
      "    OUT tensor #38: “tfl.quantize” shape=(1, 200, 200, 3), type=int8, scale=0.003921568859368563, zp=-128\n",
      "\n",
      "Step  1: CONV_2D\n",
      "    IN  tensor #38: “tfl.quantize” shape=(1, 200, 200, 3), type=int8, scale=0.003921568859368563, zp=-128\n",
      "    IN  tensor #37: “tfl.pseudo_qconst35” shape=(64, 3, 3, 3), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #36: “tfl.pseudo_qconst34” shape=(64,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #39: “sequential_1_1/sequential_1/conv2d_1/Relu;sequential_1_1/sequential_1/conv2d_1/BiasAdd;sequential_1_1/sequential_1/conv2d_1/convolution;1” shape=(1, 200, 200, 64), type=int8, scale=0.14930161833763123, zp=-128\n",
      "\n",
      "Step  2: MUL\n",
      "    IN  tensor #39: “sequential_1_1/sequential_1/conv2d_1/Relu;sequential_1_1/sequential_1/conv2d_1/BiasAdd;sequential_1_1/sequential_1/conv2d_1/convolution;1” shape=(1, 200, 200, 64), type=int8, scale=0.14930161833763123, zp=-128\n",
      "    IN  tensor #35: “tfl.pseudo_qconst33” shape=(64,), type=int8, scale=0.17310108244419098, zp=-128\n",
      "    OUT tensor #40: “sequential_1_1/sequential_1/batch_normalization_1/batchnorm/mul_1” shape=(1, 200, 200, 64), type=int8, scale=0.1682112067937851, zp=-99\n",
      "\n",
      "Step  3: ADD\n",
      "    IN  tensor #40: “sequential_1_1/sequential_1/batch_normalization_1/batchnorm/mul_1” shape=(1, 200, 200, 64), type=int8, scale=0.1682112067937851, zp=-99\n",
      "    IN  tensor #34: “tfl.pseudo_qconst32” shape=(64,), type=int8, scale=0.02051985077559948, zp=107\n",
      "    OUT tensor #41: “sequential_1_1/sequential_1/batch_normalization_1/batchnorm/add_1” shape=(1, 200, 200, 64), type=int8, scale=0.16808736324310303, zp=-99\n",
      "\n",
      "Step  4: CONV_2D\n",
      "    IN  tensor #41: “sequential_1_1/sequential_1/batch_normalization_1/batchnorm/add_1” shape=(1, 200, 200, 64), type=int8, scale=0.16808736324310303, zp=-99\n",
      "    IN  tensor #33: “tfl.pseudo_qconst31” shape=(64, 3, 3, 64), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #32: “tfl.pseudo_qconst30” shape=(64,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #42: “sequential_1_1/sequential_1/conv2d_1_2/Relu;sequential_1_1/sequential_1/conv2d_1_2/BiasAdd;sequential_1_1/sequential_1/conv2d_1_2/convolution;sequential_1_1/sequential_1/conv2d_1_2/Squeeze” shape=(1, 200, 200, 64), type=int8, scale=0.4822568893432617, zp=-128\n",
      "\n",
      "Step  5: MUL\n",
      "    IN  tensor #42: “sequential_1_1/sequential_1/conv2d_1_2/Relu;sequential_1_1/sequential_1/conv2d_1_2/BiasAdd;sequential_1_1/sequential_1/conv2d_1_2/convolution;sequential_1_1/sequential_1/conv2d_1_2/Squeeze” shape=(1, 200, 200, 64), type=int8, scale=0.4822568893432617, zp=-128\n",
      "    IN  tensor #31: “tfl.pseudo_qconst29” shape=(64,), type=int8, scale=0.010403404012322426, zp=-128\n",
      "    OUT tensor #43: “sequential_1_1/sequential_1/batch_normalization_1_2/batchnorm/mul_1” shape=(1, 200, 200, 64), type=int8, scale=0.48836034536361694, zp=-125\n",
      "\n",
      "Step  6: ADD\n",
      "    IN  tensor #43: “sequential_1_1/sequential_1/batch_normalization_1_2/batchnorm/mul_1” shape=(1, 200, 200, 64), type=int8, scale=0.48836034536361694, zp=-125\n",
      "    IN  tensor #30: “tfl.pseudo_qconst28” shape=(64,), type=int8, scale=0.0061034648679196835, zp=127\n",
      "    OUT tensor #44: “sequential_1_1/sequential_1/batch_normalization_1_2/batchnorm/add_1” shape=(1, 200, 200, 64), type=int8, scale=0.487743616104126, zp=-125\n",
      "\n",
      "Step  7: MAX_POOL_2D\n",
      "    IN  tensor #44: “sequential_1_1/sequential_1/batch_normalization_1_2/batchnorm/add_1” shape=(1, 200, 200, 64), type=int8, scale=0.487743616104126, zp=-125\n",
      "    OUT tensor #45: “sequential_1_1/sequential_1/max_pooling2d_1/MaxPool2d” shape=(1, 100, 100, 64), type=int8, scale=0.487743616104126, zp=-125\n",
      "\n",
      "Step  8: CONV_2D\n",
      "    IN  tensor #45: “sequential_1_1/sequential_1/max_pooling2d_1/MaxPool2d” shape=(1, 100, 100, 64), type=int8, scale=0.487743616104126, zp=-125\n",
      "    IN  tensor #29: “tfl.pseudo_qconst27” shape=(128, 3, 3, 64), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #28: “tfl.pseudo_qconst26” shape=(128,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #46: “sequential_1_1/sequential_1/conv2d_2_1/Relu;sequential_1_1/sequential_1/conv2d_2_1/BiasAdd;sequential_1_1/sequential_1/conv2d_2_1/convolution;” shape=(1, 100, 100, 128), type=int8, scale=0.5958064198493958, zp=-128\n",
      "\n",
      "Step  9: MUL\n",
      "    IN  tensor #46: “sequential_1_1/sequential_1/conv2d_2_1/Relu;sequential_1_1/sequential_1/conv2d_2_1/BiasAdd;sequential_1_1/sequential_1/conv2d_2_1/convolution;” shape=(1, 100, 100, 128), type=int8, scale=0.5958064198493958, zp=-128\n",
      "    IN  tensor #27: “tfl.pseudo_qconst25” shape=(128,), type=int8, scale=0.001440622960217297, zp=-128\n",
      "    OUT tensor #47: “sequential_1_1/sequential_1/batch_normalization_2_1/batchnorm/mul_1” shape=(1, 100, 100, 128), type=int8, scale=0.1463908702135086, zp=-121\n",
      "\n",
      "Step 10: ADD\n",
      "    IN  tensor #47: “sequential_1_1/sequential_1/batch_normalization_2_1/batchnorm/mul_1” shape=(1, 100, 100, 128), type=int8, scale=0.1463908702135086, zp=-121\n",
      "    IN  tensor #26: “tfl.pseudo_qconst24” shape=(128,), type=int8, scale=0.004118925426155329, zp=109\n",
      "    OUT tensor #48: “sequential_1_1/sequential_1/batch_normalization_2_1/batchnorm/add_1” shape=(1, 100, 100, 128), type=int8, scale=0.14274635910987854, zp=-121\n",
      "\n",
      "Step 11: CONV_2D\n",
      "    IN  tensor #48: “sequential_1_1/sequential_1/batch_normalization_2_1/batchnorm/add_1” shape=(1, 100, 100, 128), type=int8, scale=0.14274635910987854, zp=-121\n",
      "    IN  tensor #25: “tfl.pseudo_qconst23” shape=(128, 3, 3, 128), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #24: “tfl.pseudo_qconst22” shape=(128,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #49: “sequential_1_1/sequential_1/conv2d_3_1/Relu;sequential_1_1/sequential_1/conv2d_3_1/BiasAdd;sequential_1_1/sequential_1/conv2d_3_1/convolution;” shape=(1, 100, 100, 128), type=int8, scale=0.9574838280677795, zp=-128\n",
      "\n",
      "Step 12: MUL\n",
      "    IN  tensor #49: “sequential_1_1/sequential_1/conv2d_3_1/Relu;sequential_1_1/sequential_1/conv2d_3_1/BiasAdd;sequential_1_1/sequential_1/conv2d_3_1/convolution;” shape=(1, 100, 100, 128), type=int8, scale=0.9574838280677795, zp=-128\n",
      "    IN  tensor #23: “tfl.pseudo_qconst21” shape=(128,), type=int8, scale=0.001115808729082346, zp=-128\n",
      "    OUT tensor #50: “sequential_1_1/sequential_1/batch_normalization_3_1/batchnorm/mul_1” shape=(1, 100, 100, 128), type=int8, scale=0.09289126843214035, zp=-117\n",
      "\n",
      "Step 13: ADD\n",
      "    IN  tensor #50: “sequential_1_1/sequential_1/batch_normalization_3_1/batchnorm/mul_1” shape=(1, 100, 100, 128), type=int8, scale=0.09289126843214035, zp=-117\n",
      "    IN  tensor #22: “tfl.pseudo_qconst20” shape=(128,), type=int8, scale=0.004105701111257076, zp=127\n",
      "    OUT tensor #51: “sequential_1_1/sequential_1/batch_normalization_3_1/batchnorm/add_1” shape=(1, 100, 100, 128), type=int8, scale=0.09052053838968277, zp=-116\n",
      "\n",
      "Step 14: MAX_POOL_2D\n",
      "    IN  tensor #51: “sequential_1_1/sequential_1/batch_normalization_3_1/batchnorm/add_1” shape=(1, 100, 100, 128), type=int8, scale=0.09052053838968277, zp=-116\n",
      "    OUT tensor #52: “sequential_1_1/sequential_1/max_pooling2d_1_2/MaxPool2d” shape=(1, 50, 50, 128), type=int8, scale=0.09052053838968277, zp=-116\n",
      "\n",
      "Step 15: CONV_2D\n",
      "    IN  tensor #52: “sequential_1_1/sequential_1/max_pooling2d_1_2/MaxPool2d” shape=(1, 50, 50, 128), type=int8, scale=0.09052053838968277, zp=-116\n",
      "    IN  tensor #21: “tfl.pseudo_qconst19” shape=(256, 3, 3, 128), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #20: “tfl.pseudo_qconst18” shape=(256,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #53: “sequential_1_1/sequential_1/conv2d_4_1/Relu;sequential_1_1/sequential_1/conv2d_4_1/BiasAdd;sequential_1_1/sequential_1/conv2d_4_1/convolution;” shape=(1, 50, 50, 256), type=int8, scale=0.9490053653717041, zp=-128\n",
      "\n",
      "Step 16: MUL\n",
      "    IN  tensor #53: “sequential_1_1/sequential_1/conv2d_4_1/Relu;sequential_1_1/sequential_1/conv2d_4_1/BiasAdd;sequential_1_1/sequential_1/conv2d_4_1/convolution;” shape=(1, 50, 50, 256), type=int8, scale=0.9490053653717041, zp=-128\n",
      "    IN  tensor #19: “tfl.pseudo_qconst17” shape=(256,), type=int8, scale=0.0010407568188384175, zp=-128\n",
      "    OUT tensor #54: “sequential_1_1/sequential_1/batch_normalization_4_1/batchnorm/mul_1” shape=(1, 50, 50, 256), type=int8, scale=0.11567893624305725, zp=-114\n",
      "\n",
      "Step 17: ADD\n",
      "    IN  tensor #54: “sequential_1_1/sequential_1/batch_normalization_4_1/batchnorm/mul_1” shape=(1, 50, 50, 256), type=int8, scale=0.11567893624305725, zp=-114\n",
      "    IN  tensor #18: “tfl.pseudo_qconst16” shape=(256,), type=int8, scale=0.008151660673320293, zp=78\n",
      "    OUT tensor #55: “sequential_1_1/sequential_1/batch_normalization_4_1/batchnorm/add_1” shape=(1, 50, 50, 256), type=int8, scale=0.11381451785564423, zp=-113\n",
      "\n",
      "Step 18: CONV_2D\n",
      "    IN  tensor #55: “sequential_1_1/sequential_1/batch_normalization_4_1/batchnorm/add_1” shape=(1, 50, 50, 256), type=int8, scale=0.11381451785564423, zp=-113\n",
      "    IN  tensor #17: “tfl.pseudo_qconst15” shape=(256, 3, 3, 256), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #16: “tfl.pseudo_qconst14” shape=(256,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #56: “sequential_1_1/sequential_1/conv2d_5_1/Relu;sequential_1_1/sequential_1/conv2d_5_1/BiasAdd;sequential_1_1/sequential_1/conv2d_5_1/convolution;” shape=(1, 50, 50, 256), type=int8, scale=1.2002378702163696, zp=-128\n",
      "\n",
      "Step 19: MUL\n",
      "    IN  tensor #56: “sequential_1_1/sequential_1/conv2d_5_1/Relu;sequential_1_1/sequential_1/conv2d_5_1/BiasAdd;sequential_1_1/sequential_1/conv2d_5_1/convolution;” shape=(1, 50, 50, 256), type=int8, scale=1.2002378702163696, zp=-128\n",
      "    IN  tensor #15: “tfl.pseudo_qconst13” shape=(256,), type=int8, scale=0.09097450226545334, zp=-128\n",
      "    OUT tensor #57: “sequential_1_1/sequential_1/batch_normalization_5_1/batchnorm/mul_1” shape=(1, 50, 50, 256), type=int8, scale=0.3943060338497162, zp=-126\n",
      "\n",
      "Step 20: ADD\n",
      "    IN  tensor #57: “sequential_1_1/sequential_1/batch_normalization_5_1/batchnorm/mul_1” shape=(1, 50, 50, 256), type=int8, scale=0.3943060338497162, zp=-126\n",
      "    IN  tensor #14: “tfl.pseudo_qconst12” shape=(256,), type=int8, scale=0.003829863155260682, zp=87\n",
      "    OUT tensor #58: “sequential_1_1/sequential_1/batch_normalization_5_1/batchnorm/add_1” shape=(1, 50, 50, 256), type=int8, scale=0.39389708638191223, zp=-126\n",
      "\n",
      "Step 21: MAX_POOL_2D\n",
      "    IN  tensor #58: “sequential_1_1/sequential_1/batch_normalization_5_1/batchnorm/add_1” shape=(1, 50, 50, 256), type=int8, scale=0.39389708638191223, zp=-126\n",
      "    OUT tensor #59: “sequential_1_1/sequential_1/max_pooling2d_2_1/MaxPool2d” shape=(1, 25, 25, 256), type=int8, scale=0.39389708638191223, zp=-126\n",
      "\n",
      "Step 22: CONV_2D\n",
      "    IN  tensor #59: “sequential_1_1/sequential_1/max_pooling2d_2_1/MaxPool2d” shape=(1, 25, 25, 256), type=int8, scale=0.39389708638191223, zp=-126\n",
      "    IN  tensor #13: “tfl.pseudo_qconst11” shape=(512, 3, 3, 256), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #12: “tfl.pseudo_qconst10” shape=(512,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #60: “sequential_1_1/sequential_1/conv2d_6_1/Relu;sequential_1_1/sequential_1/conv2d_6_1/BiasAdd;sequential_1_1/sequential_1/conv2d_6_1/convolution;” shape=(1, 25, 25, 512), type=int8, scale=1.5455434322357178, zp=-128\n",
      "\n",
      "Step 23: MUL\n",
      "    IN  tensor #60: “sequential_1_1/sequential_1/conv2d_6_1/Relu;sequential_1_1/sequential_1/conv2d_6_1/BiasAdd;sequential_1_1/sequential_1/conv2d_6_1/convolution;” shape=(1, 25, 25, 512), type=int8, scale=1.5455434322357178, zp=-128\n",
      "    IN  tensor #11: “tfl.pseudo_qconst9” shape=(512,), type=int8, scale=0.0017053347546607256, zp=-128\n",
      "    OUT tensor #61: “sequential_1_1/sequential_1/batch_normalization_6_1/batchnorm/mul_1” shape=(1, 25, 25, 512), type=int8, scale=0.15267038345336914, zp=-124\n",
      "\n",
      "Step 24: ADD\n",
      "    IN  tensor #61: “sequential_1_1/sequential_1/batch_normalization_6_1/batchnorm/mul_1” shape=(1, 25, 25, 512), type=int8, scale=0.15267038345336914, zp=-124\n",
      "    IN  tensor #10: “tfl.pseudo_qconst8” shape=(512,), type=int8, scale=0.003270635614171624, zp=70\n",
      "    OUT tensor #62: “sequential_1_1/sequential_1/batch_normalization_6_1/batchnorm/add_1” shape=(1, 25, 25, 512), type=int8, scale=0.15163584053516388, zp=-124\n",
      "\n",
      "Step 25: CONV_2D\n",
      "    IN  tensor #62: “sequential_1_1/sequential_1/batch_normalization_6_1/batchnorm/add_1” shape=(1, 25, 25, 512), type=int8, scale=0.15163584053516388, zp=-124\n",
      "    IN  tensor #9: “tfl.pseudo_qconst7” shape=(512, 3, 3, 512), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #8: “tfl.pseudo_qconst6” shape=(512,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #63: “sequential_1_1/sequential_1/conv2d_7_1/Relu;sequential_1_1/sequential_1/conv2d_7_1/BiasAdd;sequential_1_1/sequential_1/conv2d_7_1/convolution;” shape=(1, 25, 25, 512), type=int8, scale=1.0951658487319946, zp=-128\n",
      "\n",
      "Step 26: MUL\n",
      "    IN  tensor #63: “sequential_1_1/sequential_1/conv2d_7_1/Relu;sequential_1_1/sequential_1/conv2d_7_1/BiasAdd;sequential_1_1/sequential_1/conv2d_7_1/convolution;” shape=(1, 25, 25, 512), type=int8, scale=1.0951658487319946, zp=-128\n",
      "    IN  tensor #7: “tfl.pseudo_qconst5” shape=(512,), type=int8, scale=0.1490822583436966, zp=-128\n",
      "    OUT tensor #64: “sequential_1_1/sequential_1/batch_normalization_7_1/batchnorm/mul_1” shape=(1, 25, 25, 512), type=int8, scale=0.6881277561187744, zp=-126\n",
      "\n",
      "Step 27: ADD\n",
      "    IN  tensor #64: “sequential_1_1/sequential_1/batch_normalization_7_1/batchnorm/mul_1” shape=(1, 25, 25, 512), type=int8, scale=0.6881277561187744, zp=-126\n",
      "    IN  tensor #6: “tfl.pseudo_qconst4” shape=(512,), type=int8, scale=0.005283291917294264, zp=113\n",
      "    OUT tensor #65: “sequential_1_1/sequential_1/batch_normalization_7_1/batchnorm/add_1” shape=(1, 25, 25, 512), type=int8, scale=0.6877288222312927, zp=-126\n",
      "\n",
      "Step 28: MAX_POOL_2D\n",
      "    IN  tensor #65: “sequential_1_1/sequential_1/batch_normalization_7_1/batchnorm/add_1” shape=(1, 25, 25, 512), type=int8, scale=0.6877288222312927, zp=-126\n",
      "    OUT tensor #66: “sequential_1_1/sequential_1/max_pooling2d_3_1/MaxPool2d” shape=(1, 12, 12, 512), type=int8, scale=0.6877288222312927, zp=-126\n",
      "\n",
      "Step 29: RESHAPE\n",
      "    IN  tensor #66: “sequential_1_1/sequential_1/max_pooling2d_3_1/MaxPool2d” shape=(1, 12, 12, 512), type=int8, scale=0.6877288222312927, zp=-126\n",
      "    IN  tensor #1: “arith.constant” shape=(2,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #67: “sequential_1_1/sequential_1/flatten_1/Reshape” shape=(1, 73728), type=int8, scale=0.6877288222312927, zp=-126\n",
      "\n",
      "Step 30: FULLY_CONNECTED\n",
      "    IN  tensor #67: “sequential_1_1/sequential_1/flatten_1/Reshape” shape=(1, 73728), type=int8, scale=0.6877288222312927, zp=-126\n",
      "    IN  tensor #5: “tfl.pseudo_qconst3” shape=(512, 73728), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #4: “tfl.pseudo_qconst2” shape=(512,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #68: “sequential_1_1/sequential_1/dense_1/MatMul;sequential_1_1/sequential_1/dense_1/Relu;sequential_1_1/sequential_1/dense_1/BiasAdd” shape=(1, 512), type=int8, scale=4.46315336227417, zp=-128\n",
      "\n",
      "Step 31: FULLY_CONNECTED\n",
      "    IN  tensor #68: “sequential_1_1/sequential_1/dense_1/MatMul;sequential_1_1/sequential_1/dense_1/Relu;sequential_1_1/sequential_1/dense_1/BiasAdd” shape=(1, 512), type=int8, scale=4.46315336227417, zp=-128\n",
      "    IN  tensor #3: “tfl.pseudo_qconst1” shape=(29, 512), type=int8, scale=0.0, zp=0\n",
      "    IN  tensor #2: “tfl.pseudo_qconst” shape=(29,), type=int32, scale=0.0, zp=0\n",
      "    OUT tensor #69: “sequential_1_1/sequential_1/batch_normalization_8_1/batchnorm/mul_1;sequential_1_1/sequential_1/batch_normalization_8_1/batchnorm/add_1;sequential_1_1/sequential_1/logits_1/MatMul;sequential_1_1/sequential_1/logits_1/BiasAdd” shape=(1, 29), type=int8, scale=0.3223066031932831, zp=-18\n",
      "\n",
      "Step 32: SOFTMAX\n",
      "    IN  tensor #69: “sequential_1_1/sequential_1/batch_normalization_8_1/batchnorm/mul_1;sequential_1_1/sequential_1/batch_normalization_8_1/batchnorm/add_1;sequential_1_1/sequential_1/logits_1/MatMul;sequential_1_1/sequential_1/logits_1/BiasAdd” shape=(1, 29), type=int8, scale=0.3223066031932831, zp=-18\n",
      "    OUT tensor #70: “StatefulPartitionedCall_1:01” shape=(1, 29), type=int8, scale=0.00390625, zp=-128\n",
      "\n",
      "Step 33: QUANTIZE\n",
      "    IN  tensor #70: “StatefulPartitionedCall_1:01” shape=(1, 29), type=int8, scale=0.00390625, zp=-128\n",
      "    OUT tensor #71: “StatefulPartitionedCall_1:0” shape=(1, 29), type=uint8, scale=0.00390625, zp=0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tflite_runtime.interpreter import Interpreter   # <— note the change!\n",
    "\n",
    "# 1) Load the interpreter WITHOUT any delegates and preserve intermediates\n",
    "interp = Interpreter(\n",
    "    model_path=\"asl_model_quantized_int8.tflite\",\n",
    "    experimental_preserve_all_tensors=True\n",
    "    # no 'experimental_delegates' here – tflite-runtime has none by default\n",
    ")\n",
    "interp.allocate_tensors()\n",
    "\n",
    "# 2) Build a dict of tensor details\n",
    "tensor_details = { d[\"index\"]: d for d in interp.get_tensor_details() }\n",
    "\n",
    "# 3) Fetch the raw operator list\n",
    "ops = interp._get_ops_details()\n",
    "\n",
    "print(\"\\nExecution steps (pure‑TFLite CPU ops):\\n\")\n",
    "for step, op in enumerate(ops):\n",
    "    print(f\"Step {step:2d}: {op['op_name']}\")\n",
    "    def desc(tidx, role):\n",
    "        d = tensor_details[tidx]\n",
    "        shape = tuple(d[\"shape\"])\n",
    "        dtype = np.dtype(d[\"dtype\"]).name\n",
    "        q = d.get(\"quantization\")\n",
    "        if q:\n",
    "            scale, zp = q\n",
    "        else:\n",
    "            scales = d[\"quantization_parameters\"][\"scales\"]\n",
    "            zps    = d[\"quantization_parameters\"][\"zero_points\"]\n",
    "            scale = float(scales[0]) if len(scales)>0 else None\n",
    "            zp    = int(zps[0])    if len(zps)>0    else None\n",
    "        return f\"    {role} tensor #{tidx}: “{d['name']}” shape={shape}, type={dtype}, scale={scale}, zp={zp}\"\n",
    "    for tid in op[\"inputs\"]:\n",
    "        print(desc(tid, \"IN \"))\n",
    "    for tid in op[\"outputs\"]:\n",
    "        print(desc(tid, \"OUT\"))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49620e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donald/.local/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "/home/donald/.local/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:465: UserWarning: Warning: Enabling `experimental_preserve_all_tensors` with the BUILTIN or AUTO op resolver is intended for debugging purposes only. Be aware that this can significantly increase memory usage by storing all intermediate tensors. If you encounter memory problems or are not actively debugging, consider disabling this option.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 71 tensors to data/model_dump.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "def sanitize(name):\n",
    "    return re.sub(r'[^0-9a-zA-Z_]', '_', name)\n",
    "\n",
    "# 1) Load & prepare the interpreter\n",
    "interp = Interpreter(\n",
    "    model_path=\"asl_model_quantized_int8.tflite\",\n",
    "    experimental_preserve_all_tensors=True\n",
    ")\n",
    "interp.allocate_tensors()\n",
    "\n",
    "# 2) Load your JPEG, resize to 200×200, and set it as the input\n",
    "img = Image.open(\"asl_alphabet_test/C_test.jpg\").convert(\"RGB\").resize((200,200))\n",
    "input_arr = np.array(img, dtype=np.uint8)[None, ...]   # shape (1,200,200,3)\n",
    "\n",
    "in_idx = interp.get_input_details()[0][\"index\"]\n",
    "interp.set_tensor(in_idx, input_arr)\n",
    "\n",
    "# 3) Run the graph so QUANTIZE and all other ops execute\n",
    "interp.invoke()\n",
    "\n",
    "# 4) Now dump to JSON\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "model_json = {}\n",
    "\n",
    "for detail in interp.get_tensor_details():\n",
    "    name   = detail[\"name\"]\n",
    "    scales = detail[\"quantization_parameters\"][\"scales\"]\n",
    "    zps    = detail[\"quantization_parameters\"][\"zero_points\"]\n",
    "\n",
    "    # only keep truly‑quantized tensors\n",
    "    if scales.size == 0 or scales[0] == 0.0:\n",
    "        continue\n",
    "\n",
    "    idx = detail[\"index\"]\n",
    "    try:\n",
    "        arr = interp.get_tensor(idx)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    entry = {\n",
    "      \"shape\":      [int(d) for d in detail[\"shape\"]],\n",
    "      \"dtype\":      np.dtype(detail[\"dtype\"]).name,\n",
    "      \"scale\":      float(scales[0]),\n",
    "      \"zero_point\": int(zps[0]),\n",
    "      \"data\":       arr.flatten().tolist()\n",
    "    }\n",
    "    model_json[name] = entry\n",
    "\n",
    "with open(\"data/model_dump.json\", \"w\") as f:\n",
    "    json.dump(model_json, f, indent=2)\n",
    "\n",
    "print(f\"Wrote {len(model_json)} tensors to data/model_dump.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "725e57eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 values:\n",
      "  Python: 54, 38, 12\n",
      "   C++  : 54, 38, 12\n",
      "Last  3 values:\n",
      "  Python: -60, -69, -79\n",
      "   C++  : -60, -69, -79\n",
      "tfl.quantize\n",
      "Total elements : 120000\n",
      "Mismatches     : 0\n",
      "Maximum error  : 0\n"
     ]
    }
   ],
   "source": [
    "py_out = None\n",
    "# 1) Load the C++ output\n",
    "import numpy as np\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "# 1) Load the C++ output\n",
    "cpp_path = \"../CPP_Model/cpp_out/tfl_quantize_output.bin\"\n",
    "cpp_out  = np.fromfile(cpp_path, dtype=np.int8)\n",
    "\n",
    "# 2) Run the Python TFLite quantize op\n",
    "interp = Interpreter(\n",
    "    model_path=\"asl_model_quantized_int8.tflite\",\n",
    "    experimental_preserve_all_tensors=True\n",
    ")\n",
    "interp.allocate_tensors()\n",
    "\n",
    "# (Re‑set the same input as you used in C++)\n",
    "from PIL import Image\n",
    "img = Image.open(\"asl_alphabet_test/C_test.jpg\").convert(\"RGB\").resize((200,200))\n",
    "inp = np.array(img, np.uint8)[None,...]\n",
    "interp.set_tensor(interp.get_input_details()[0][\"index\"], inp)\n",
    "\n",
    "interp.invoke()\n",
    "\n",
    "# find the tfl.quantize tensor\n",
    "py_out = None\n",
    "for d in interp.get_tensor_details():\n",
    "    if d[\"name\"] == \"tfl.quantize\":\n",
    "        py_out = interp.get_tensor(d[\"index\"]).astype(np.int8).flatten()\n",
    "        break\n",
    "assert py_out is not None, \"tfl.quantize tensor not found\"\n",
    "\n",
    "# 3) Print first and last 3 values\n",
    "def fmt(arr):\n",
    "    return \", \".join(f\"{int(x)}\" for x in arr)\n",
    "\n",
    "print(\"First 3 values:\")\n",
    "print(f\"  Python: {fmt(py_out[:3])}\")\n",
    "print(f\"   C++  : {fmt(cpp_out[:3])}\")\n",
    "\n",
    "print(\"Last  3 values:\")\n",
    "print(f\"  Python: {fmt(py_out[-3:])}\")\n",
    "print(f\"   C++  : {fmt(cpp_out[-3:])}\")\n",
    "\n",
    "cpp_out  = np.fromfile(cpp_path, dtype=np.int8)\n",
    "\n",
    "for d in interp.get_tensor_details():\n",
    "    if d[\"name\"] == \"tfl.quantize\":\n",
    "        print(d[\"name\"])\n",
    "        py_out = interp.get_tensor(d[\"index\"]).astype(np.int8).flatten()\n",
    "        break\n",
    "assert py_out is not None, \"tfl.quantize tensor not found\"\n",
    "\n",
    "\n",
    "# 3) Check shapes match\n",
    "if py_out.shape != cpp_out.shape:\n",
    "    raise ValueError(f\"Shape mismatch: python {py_out.shape}, cpp {cpp_out.shape}\")\n",
    "\n",
    "# 4) Compare\n",
    "diff = py_out.astype(int) - cpp_out.astype(int)\n",
    "n_mismatch = np.count_nonzero(diff)\n",
    "max_err    = np.max(np.abs(diff)) if n_mismatch else 0\n",
    "\n",
    "print(f\"Total elements : {py_out.size}\")\n",
    "print(f\"Mismatches     : {n_mismatch}\")\n",
    "print(f\"Maximum error  : {max_err}\")\n",
    "\n",
    "if n_mismatch:\n",
    "    idx0 = np.nonzero(diff)[0][0]\n",
    "    print(f\"\\nFirst mismatch at index {idx0}:\")\n",
    "    print(f\"  Python: {py_out[idx0]} (0x{py_out[idx0]&0xFF:02X})\")\n",
    "    print(f\"  C++   : {cpp_out[idx0]} (0x{cpp_out[idx0]&0xFF:02X})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "839140a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stage 0 (tfl.quantize) ---\n",
      "  ref.shape = (120000,), cpp.shape = (120000,)\n",
      "  Total elems : 120000\n",
      "  Matches     : 515\n",
      "  Mismatches  : 119485\n",
      "  First 5 ref : [54, 38, 12, 54, 38]\n",
      "  First 5 cpp : [112, 1, 7, 75, -18]\n",
      "  Last  5 ref : [-75, -83, -60, -69, -79]\n",
      "  Last  5 cpp : [-19, -19, -1, -128, -128]\n",
      "  First mismatch at idx 0: ref=54, cpp=112\n",
      "\n",
      "--- Stage 1 (sequential_1_1/sequential_1/conv2d_1/Relu;sequential_1_1/sequential_1/conv2d_1/BiasAdd;sequential_1_1/sequential_1/conv2d_1/convolution;1) ---\n",
      "  ref.shape = (2560000,), cpp.shape = (2560000,)\n",
      "  Total elems : 2560000\n",
      "  Matches     : 692385\n",
      "  Mismatches  : 1867615\n",
      "  First 5 ref : [-128, -126, -124, -125, -126]\n",
      "  First 5 cpp : [127, -128, -128, 127, -128]\n",
      "  Last  5 ref : [-128, -128, -128, -127, -128]\n",
      "  Last  5 cpp : [-128, 127, 127, 127, -128]\n",
      "  First mismatch at idx 0: ref=-128, cpp=127\n",
      "\n",
      "--- Stage 2 (sequential_1_1/sequential_1/batch_normalization_1/batchnorm/mul_1) ---\n",
      "  ref.shape = (2560000,), cpp.shape = (2560000,)\n",
      "  Total elems : 2560000\n",
      "  Matches     : 692385\n",
      "  Mismatches  : 1867615\n",
      "  First 5 ref : [-99, -96, -25, -89, -87]\n",
      "  First 5 cpp : [-128, -99, -99, 127, -99]\n",
      "  Last  5 ref : [-99, -99, -99, -97, -99]\n",
      "  Last  5 cpp : [-99, -128, 127, -128, -99]\n",
      "  First mismatch at idx 0: ref=-99, cpp=-128\n",
      "\n",
      "--- Stage 3 (sequential_1_1/sequential_1/batch_normalization_1/batchnorm/add_1) ---\n",
      "  ref.shape = (2560000,), cpp.shape = (2560000,)\n",
      "  Total elems : 2560000\n",
      "  Matches     : 160265\n",
      "  Mismatches  : 2399735\n",
      "  First 5 ref : [-99, -102, -35, -98, -101]\n",
      "  First 5 cpp : [127, 127, 127, 127, 127]\n",
      "  Last  5 ref : [-99, -99, -108, -102, -99]\n",
      "  Last  5 cpp : [127, 127, 127, 127, -99]\n",
      "  First mismatch at idx 0: ref=-99, cpp=127\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# === CONFIG ===\n",
    "JSON_PATH = \"data/model_dump.json\"\n",
    "STAGES = [\n",
    "    # (stage_name, json_key, bin_file, dtype)\n",
    "    (0, \"tfl.quantize\",     \"../CPP_Model/step0_quant.bin\",  np.int8),\n",
    "    (1, \"sequential_1_1/sequential_1/conv2d_1/Relu;sequential_1_1/sequential_1/conv2d_1/BiasAdd;sequential_1_1/sequential_1/conv2d_1/convolution;1\",\n",
    "          \"../CPP_Model/step1_conv.bin\",   np.int8),\n",
    "    (2, \"sequential_1_1/sequential_1/batch_normalization_1/batchnorm/mul_1\",\n",
    "          \"../CPP_Model/step2_mul.bin\",    np.int8),\n",
    "    (3, \"sequential_1_1/sequential_1/batch_normalization_1/batchnorm/add_1\",\n",
    "          \"../CPP_Model/step3_add.bin\",    np.int8),\n",
    "]\n",
    "\n",
    "# === LOAD JSON ONCE ===\n",
    "with open(JSON_PATH, \"r\") as f:\n",
    "    model = json.load(f)\n",
    "\n",
    "# === COMPARE EACH STAGE ===\n",
    "for stage, key, binpath, dtype in STAGES:\n",
    "    meta = model[key]\n",
    "    ref = np.array(meta[\"data\"], dtype=dtype)\n",
    "    cpp = np.fromfile(binpath, dtype=dtype)\n",
    "\n",
    "    print(f\"\\n--- Stage {stage} ({key}) ---\")\n",
    "    print(f\"  ref.shape = {ref.shape}, cpp.shape = {cpp.shape}\")\n",
    "    assert ref.shape == cpp.shape, \"Shape mismatch!\"\n",
    "\n",
    "    matches    = (ref == cpp)\n",
    "    n_total    = ref.size\n",
    "    n_matches  = int(np.count_nonzero(matches))\n",
    "    n_mismatch = n_total - n_matches\n",
    "\n",
    "    print(f\"  Total elems : {n_total}\")\n",
    "    print(f\"  Matches     : {n_matches}\")\n",
    "    print(f\"  Mismatches  : {n_mismatch}\")\n",
    "\n",
    "    # show a few samples\n",
    "    K = 5\n",
    "    print(f\"  First {K} ref : {ref[:K].tolist()}\")\n",
    "    print(f\"  First {K} cpp : {cpp[:K].tolist()}\")\n",
    "    print(f\"  Last  {K} ref : {ref[-K:].tolist()}\")\n",
    "    print(f\"  Last  {K} cpp : {cpp[-K:].tolist()}\")\n",
    "\n",
    "    if n_mismatch:\n",
    "        idx = int(np.nonzero(~matches)[0][0])\n",
    "        print(f\"  First mismatch at idx {idx}: ref={int(ref[idx])}, cpp={int(cpp[idx])}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
